{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting numpy>=1.24 (from geopandas)\n",
      "  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from geopandas) (23.2)\n",
      "Collecting pandas>=2.0.0 (from geopandas)\n",
      "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyproj>=3.5.0 (from geopandas)\n",
      "  Using cached pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->geopandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.0.0->geopandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from pyogrio>=0.7.2->geopandas) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n",
      "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.4/338.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyogrio-0.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (27.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
      "Downloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pyproj, numpy, et-xmlfile, shapely, pyogrio, pandas, openpyxl, geopandas\n",
      "Successfully installed et-xmlfile-2.0.0 geopandas-1.1.1 numpy-2.3.1 openpyxl-3.1.5 pandas-2.3.0 pyogrio-0.11.0 pyproj-3.7.1 shapely-2.1.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8sggRZaRhEK",
    "outputId": "c6ca5557-38c3-42b1-92a0-aaee446c2c92"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpds\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from shapely import wkt\n",
    "from openpyxl import load_workbook\n",
    "import geopandas as gpds\n",
    "import sys\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "eKMp4AirW5ue",
    "outputId": "1ae04056-ab2a-4197-9ac5-eee6b4919a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files:\n",
      "1: 2024_Advancement.xlsx\n",
      "2: 2023_Advancement.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 3 for 2023 or 4 for 2024:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file: /projects/illinois/aces/cropsci/ese/SoyData/advaymb2/2024_Advancement.xlsx\n"
     ]
    }
   ],
   "source": [
    "# FieldMap visualizer based on two Excel files - one with the plot-based data, \n",
    "# and another that has the geometric representation of the field plots\n",
    "# The user first reads-in the data file- and selects a location\n",
    "# based on the selected location, the data file is filtered for that location\n",
    "# followed by the Field map file being opened and used for extracting the polygons for each plot for the selected trial\n",
    "\n",
    "# Define the directory path\n",
    "directory = \"/projects/illinois/aces/cropsci/ese/SoyData/advaymb2/\"\n",
    "\n",
    "# Search for files matching '2023' or '2024' in the directory\n",
    "file_pattern = re.compile(r\"202[3-4]*_Advancement.xlsx\")\n",
    "matching_files = [f for f in os.listdir(directory) if file_pattern.match(f)]\n",
    "\n",
    "# Ensure there are matching files\n",
    "if not matching_files:\n",
    "    raise FileNotFoundError(\"No matching files found for 2023 or 2024.\")\n",
    "\n",
    "# Display available options\n",
    "print(\"Available files:\")\n",
    "for i, file in enumerate(matching_files, 1):\n",
    "    print(f\"{i}: {file}\")\n",
    "\n",
    "# Ask the user to select a file by choosing 3 or 4\n",
    "while True:\n",
    "    user_choice = input(\"Enter 3 for 2023 or 4 for 2024: \").strip()\n",
    "    \n",
    "    if user_choice in [\"3\", \"4\"]:\n",
    "        selected_year = f\"202{user_choice}\"\n",
    "        selected_file = next((f for f in matching_files if f.startswith(selected_year)), None)\n",
    "        if selected_file:\n",
    "            break\n",
    "        else:\n",
    "            print(f\"No file found for {selected_year}, please try again.\")\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 3 or 4.\")\n",
    "\n",
    "# Construct full file path\n",
    "file_path = os.path.join(directory, selected_file)\n",
    "\n",
    "print(f\"Selected file: {file_path}\")\n",
    "#advaymb2-projects/SoyData/advaymb2/output/Copy of 2023 Perry Soybean map.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheets in the Excel file:\n",
      "1: list\n",
      "2: MO\n",
      "3: NE\n",
      "4: IA\n",
      "5: VT\n",
      "6: UM\n",
      "7: list (2)\n",
      "8: agro\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the index number of the sheet you want to load:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You selected: VT\n"
     ]
    }
   ],
   "source": [
    "# Characters that represent missing data\n",
    "na_characters = [-9, \"-9\", \"\"]\n",
    "\n",
    "# Load the Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# List available sheets\n",
    "sheet_names = xls.sheet_names\n",
    "print(\"Available sheets in the Excel file:\")\n",
    "for i, sheet in enumerate(sheet_names, 1):\n",
    "    print(f\"{i}: {sheet}\")\n",
    "\n",
    "# Prompt user to select a sheet by index\n",
    "while True:\n",
    "    sheet_index = input(\"\\nEnter the index number of the sheet you want to load: \").strip()\n",
    "    \n",
    "    if sheet_index.isdigit():\n",
    "        sheet_index = int(sheet_index)\n",
    "        if 1 <= sheet_index <= len(sheet_names):\n",
    "            selected_sheet = sheet_names[sheet_index - 1]\n",
    "            print(f\"\\nYou selected: {selected_sheet}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Please enter a number between 1 and {len(sheet_names)}.\")\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "# Read the selected sheet\n",
    "df = pd.read_excel(xls, sheet_name=selected_sheet, header=0, na_values=na_characters, skiprows=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    'QR code',         'ent',        'name',      'FPhilm',\n",
       "             'Trial',        'test',        'plot',         'FP2',\n",
       "                'Ht',         'Pod',         'Mat',         'Lod',\n",
       "               'Yld',        'oil ',     'protein',       'notes',\n",
       "               'rep',         'loc',        'locc',         'rng',\n",
       "               'row',         'run',       'field',     'Sds/env',\n",
       "       'Unnamed: 24',      'source', 'Unnamed: 26', 'Unnamed: 27',\n",
       "           'parents',       'trait',             0,       '2.5.7',\n",
       "              'geno',       '1,2,3',   'Reg tests',     'Variety',\n",
       "       'Unnamed: 36'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique locations: ['Belleville' 'Dekalb' 'Freeport' 'Goodfield' 'Monmouth' 'Perry'\n",
      " 'St. Peter']\n",
      "Available locations:\n",
      "1: Belleville\n",
      "2: Dekalb\n",
      "3: Freeport\n",
      "4: Goodfield\n",
      "5: Monmouth\n",
      "6: Perry\n",
      "7: St. Peter\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the index number of the location you want:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You selected: Belleville\n"
     ]
    }
   ],
   "source": [
    "### Ensure the column 'loc' exists\n",
    "# if it does capture the names of the available locations\n",
    "if 'loc' in df.columns:\n",
    "    locations_available = df['loc'].dropna().unique()  # Drop NaNs before getting unique values\n",
    "    print(\"Unique locations:\", locations_available)\n",
    "else:\n",
    "    raise KeyError(\"Column 'loc' not found in the dataframe.\")\n",
    "\n",
    "# Display available options for locations\n",
    "print(\"Available locations:\")\n",
    "for i, loc in enumerate(locations_available, 1):\n",
    "    print(f\"{i}: {loc}\")\n",
    "    \n",
    "# Ask the user to select a location by choosing an index\n",
    "while True:\n",
    "    user_choice = input(\"\\nEnter the index number of the location you want: \").strip()\n",
    "    \n",
    "    # Ensure user input is a valid integer\n",
    "    if user_choice.isdigit():\n",
    "        user_choice = int(user_choice)\n",
    "        \n",
    "        # Check if the index is within the valid range\n",
    "        if 1 <= user_choice <= len(locations_available):\n",
    "            selected_location = locations_available[user_choice - 1]  # Convert index to value\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Invalid choice. Please enter a number between 1 and {len(locations_available)}.\")\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "# Print selected location\n",
    "print(f\"\\nYou selected: {selected_location}\")\n",
    "filtered_data = df[df['loc'] == selected_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded map file: /projects/illinois/aces/cropsci/ese/SoyData/advaymb2/input/2024 Belleville Soybean map.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Find the Map file corresponding to the data file\n",
    "input_folder = \"/projects/illinois/aces/cropsci/ese/SoyData/advaymb2/input/\" \n",
    "pattern = re.compile(rf\"{selected_year} {selected_location} Soybean [Mm]ap\\.xlsx\")\n",
    "\n",
    "# Search for the map file in the directory\n",
    "matching_files = [f for f in os.listdir(input_folder) if pattern.fullmatch(f)]\n",
    "\n",
    "if not matching_files:\n",
    "    raise FileNotFoundError(f\"No map file found for {selected_year} {selected_location}\")\n",
    "\n",
    "# Assume first match is the desired one\n",
    "map_file_name = matching_files[0]\n",
    "map_file_path = os.path.join(input_folder, map_file_name)\n",
    "\n",
    "# Load the map file\n",
    "selected_loc_map = pd.read_excel(map_file_path, sheet_name=0)  # Adjust sheet_name if needed\n",
    "print(f\"Loaded map file: {map_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDictionary = {}\n",
    "dataDictionary = filtered_data.columns\n",
    "dataDictionary = {'QR code':'QR code for the plot',\n",
    "            'ent':'entry id for the trial and location',\n",
    "            'name': 'line identifier' ,      \n",
    "            'FPhilm':'Flower color(P:purple,W:White,M:Mix, 1 character)-Pubescence(Lt,Gi,2characters)-Hilum color: 6genes(I,T,R,O,W1,Wp),2 to 4 characters',\n",
    "            'trial': 'year(2digits)+trial type(2digits)+ some string( 1 letter)',\n",
    "            'test': 'trial identifier + 2 or 3 letters for Location',        \n",
    "            'plot': 'plot identifier unique to each location',         \n",
    "            'FP2': 'Flower color, often empty in the files',\n",
    "            'Ht': 'Height, measured',         \n",
    "            'Pod': 'Pod Color: b,m,t',         \n",
    "            'Mat': 'estimated maturity date: 9- is for September, the two digits that follow are the calendar days of September, if bleeds over 30, implies October',         \n",
    "            'Lod': 'lodging score, lower is better',\n",
    "            'Yld': 'Yield, standardized to 13% moisture by combine',         \n",
    "            'oil': 'combine measured - NIR based',     \n",
    "            'protein': 'Combine measured- NIR based',       \n",
    "            'notes': 'free text area for note taker',\n",
    "            'rep': 'replicate within location, often 2 for VT trials',         \n",
    "            'loc': 'location name',        \n",
    "            'locc': 'location code, 1 to 3 capital letters',         \n",
    "            'rng': 'range where the plot is located',\n",
    "            'row': 'row where the plot is located',         \n",
    "            'run': 'not sure what this is',       \n",
    "            'field': 'field identifier within each location',     \n",
    "            'Sds/env': 'Seeds planted- aimed at 800 at later stage trials, can be as low as 200 for early trials',\n",
    "            'source': 'line identifier from previous season seed increase', \n",
    "            'Unnamed: 25':'not sure - drop', \n",
    "            'Unnamed: 26': 'not sure - drop',     \n",
    "            'parents': 'parents of the tested line- female x male',\n",
    "            'trait': 'Breeding objective/selection target: HOLL :High-Oleic-Low-Linoleic, Rhg1, Rhg4, etc. ',             \n",
    "            '0': 'SCN isolate with Type-0 cyst count on the variety based on GH inoculation',       \n",
    "            '2.5.7':'SCN isolate with Type-2.5.7 cyst count on the variety based on GH inoculation',        \n",
    "            'geno':'Genotypes of the SCN resistance alleles.There are 4 total genes, 2 derived from PI88788, and another 2 derived from Peking, listed as 4 capital letters, each letter chooses from S(usceptible)/R(esistant)',\n",
    "            '1,2,3': 'not sure',   \n",
    "            'Reg tests' : 'Name of the trial type: UT- uniform trials, Sp,PT, MSmC, etc.',     \n",
    "            'Variety' : 'Commercial Names of the released varieties', \n",
    "            'Unnamed: 35' : 'Randomization index'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yN51KbjT_K2c"
   },
   "outputs": [],
   "source": [
    "# functions for I/O\n",
    "\n",
    "# Find the starting row index that contains plot identifiers 1, 2, and 3\n",
    "def find_head(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        row_values = set(row.dropna().astype(str))\n",
    "        if {'1.0', '2.0', '3.0'}.issubset(row_values):\n",
    "            return index + 1\n",
    "    raise ValueError(\"Could not find a row containing '1', '2', and '3'\")\n",
    "\n",
    "# Find the starting column index (assumes columns are named like 'Range_5', 'Col_6', etc.)\n",
    "def find_col(dataframe):\n",
    "    for col_name, col in dataframe.items():\n",
    "        col_values = set(col.dropna().astype(str))\n",
    "        if {'1.0', '2.0', '3.0'}.issubset(col_values):\n",
    "            match = re.search(r'(\\d+)$', col_name)  # Extract trailing number\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "    raise ValueError(\"Could not find a column containing '1', '2', and '3'\")\n",
    "\n",
    "# Create WKT polygon from string coordinates (not recommended for numeric math)\n",
    "def create_polygon(col, row):\n",
    "    col = int(col)\n",
    "    row = int(row)\n",
    "    return (\n",
    "        f\"POLYGON (({col} {row}, {col+1} {row}, {col+1} {row+1}, \"\n",
    "        f\"{col} {row+1}, {col} {row}))\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find a row containing '1', '2', and '3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mfind_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_loc_map\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(find_col(selected_loc_map))\n\u001b[1;32m      3\u001b[0m create_polygon(col,row)\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36mfind_head\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.0\u001b[39m\u001b[38;5;124m'\u001b[39m}\u001b[38;5;241m.\u001b[39missubset(row_values):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a row containing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find a row containing '1', '2', and '3'"
     ]
    }
   ],
   "source": [
    "row = str(find_head(selected_loc_map))\n",
    "col = str(find_col(selected_loc_map))\n",
    "create_polygon(col,row)\n",
    "\n",
    "# will use file_1 to get the row & col coordinates for location\n",
    "# will use file_2 get the geometry of the trial in location\n",
    "# generate a polygon file per location\n",
    "# wisua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_records = []\n",
    "\n",
    "def write_polygon_records(value, file_path=selected_location, sheet_name=selected_sheet, col=col, row=row):\n",
    "    # Load workbook\n",
    "    wb = load_workbook(file_path)\n",
    "    \n",
    "    # Get the correct worksheet\n",
    "    ws = wb[sheet_name] if sheet_name in wb.sheetnames else wb.active\n",
    "    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=19, max_col=19):\n",
    "        for cell in row:\n",
    "          print()\n",
    "    # Record this update for CSV export\n",
    "    polygon_records.append({\n",
    "        \"sheet\": sheet_name,\n",
    "        \"row\": row,\n",
    "        \"col\": col,\n",
    "        \"polygon_wkt\": value\n",
    "    })\n",
    "\n",
    "    # Save the Excel workbook back if needed (optional)\n",
    "    # wb.save(file_path)  # You can skip this if not updating the .xlsx\n",
    "\n",
    "    # ---- CSV export logic below ----\n",
    "\n",
    "    # Build CSV file path based on original file name\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]  # no extension\n",
    "    output_folder = os.path.dirname(file_path)\n",
    "    output_file_name = base_name + \"_polygons.csv\"\n",
    "    output_csv_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "    # Convert to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(polygon_records)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"✅ Polygon saved to cell ({row}, {col}) in sheet '{sheet_name}'\")\n",
    "    print(f\"📁 Polygon record written to: {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, output_file_name)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Save the DataFrame or GeoDataFrame to CSV\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43myour_dataframe\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolygon data written to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'your_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "def fill_cell(col, row, value):\n",
    "  wb = selected_loc_map\n",
    "  ws = wb[\"A\"]\n",
    "  for row in ws.iter_rows(min_row=find_row, max_row=ws.max_row, min_col=find_col, max_col=19):\n",
    "    for cell in row:\n",
    "      print()\n",
    "  ws.cell(row, col).value = value\n",
    " # wb.save(\"/projects/illinois/aces/cropsci/ese/SoyData/advaymb2/output/Copy of\" + selected_location + selected_year +\".xlsx\")\n",
    "\n",
    "input_path = map_file_path  # The path you used to load the map\n",
    "base_name = os.path.splitext(os.path.basename(input_path))[0]  # e.g. \"2023 Goodfield Soybean Map\"\n",
    "folder = os.path.dirname(input_path)  # Get the input folder path\n",
    "\n",
    "# Construct the output file name\n",
    "output_file_name = base_name + \"_polygons.csv\"\n",
    "output_path = os.path.join(folder, output_file_name)\n",
    "\n",
    "# Save the DataFrame or GeoDataFrame to CSV\n",
    "your_dataframe.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Polygon data written to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfill_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m, in \u001b[0;36mfill_cell\u001b[0;34m(col, row, value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill_cell\u001b[39m(col, row, value):\n\u001b[1;32m      2\u001b[0m   wb \u001b[38;5;241m=\u001b[39m selected_loc_map\n\u001b[0;32m----> 3\u001b[0m   ws \u001b[38;5;241m=\u001b[39m \u001b[43mwb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ws\u001b[38;5;241m.\u001b[39miter_rows(min_row\u001b[38;5;241m=\u001b[39mfind_row, max_row\u001b[38;5;241m=\u001b[39mws\u001b[38;5;241m.\u001b[39mmax_row, min_col\u001b[38;5;241m=\u001b[39mfind_col, max_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'"
     ]
    }
   ],
   "source": [
    "fill_cell(col,row,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Jkfm7Juq08lu"
   },
   "outputs": [],
   "source": [
    "def mapper(field_name, write_to):\n",
    "  output_name = selected_year + selected_location + \" MapFile-polygons.txt\"\n",
    "  field_wb = selected_loc_map\n",
    "  field_ws = field_wb[\"A\"]\n",
    "  wb = field_wb\n",
    "  ws = wb[\"\"]\n",
    "\n",
    "  beginning_row = find_head(file_name)\n",
    "  beginning_col = find_col(file_name)\n",
    "  idx = 1\n",
    "  for row in ws.iter_rows(max_row = ws.max_row - 1, min_col=19, max_col=19):\n",
    "    for cell in row:\n",
    "      if cell.value == field_name:\n",
    "        #print(str(ws.cell(idx, 7).value))\n",
    "        starting_row = beginning_row\n",
    "        while(starting_row < 60):\n",
    "          starting_row += 1\n",
    "          col = beginning_col\n",
    "          while(col < 30):\n",
    "            col += 1\n",
    "            #print(\"plot: \" + str(field_ws.cell(starting_row, col).value))\n",
    "            #print(str(ws.cell(idx, 7).value))\n",
    "            if str(field_ws.cell(starting_row, col).value) == str(int(ws.cell(idx, 7).value)):\n",
    "              #print(\"plot: \" + str(int(ws.cell(idx, 7).value)))\n",
    "              #print(\"row: \" + str(starting_row))\n",
    "              #print(\"col: \" + str(col))\n",
    "              ws.cell(idx, 8).value = (\"POLYGON ((\"+str(field_ws.cell(beginning_row, col).value)+\" \"\n",
    "                                       +str(field_ws.cell(starting_row, beginning_col).value)+\", \"\n",
    "                                       + str(field_ws.cell(beginning_row, col).value + 1) +\" \"\n",
    "                                       +str(field_ws.cell(starting_row, beginning_col).value)+\", \"\n",
    "                                       + str(field_ws.cell(beginning_row, col).value + 1) +\" \"\n",
    "                                       + str(field_ws.cell(starting_row, beginning_col).value + 1) +\", \"\n",
    "                                       +str(field_ws.cell(beginning_row, col).value)+\" \"\n",
    "                                       + str(field_ws.cell(starting_row, beginning_col).value + 1) +\", \"\n",
    "                                       +str(field_ws.cell(beginning_row, col).value)+\" \"\n",
    "                                       +str(field_ws.cell(starting_row, beginning_col).value)+\"))\")\n",
    "\n",
    "\n",
    "    idx += 1\n",
    "  wb.save(\"/projects/illinois/aces/cropsci/ese/SoyData/advaymb2/output/\"+ output_name)\n",
    "\n",
    "\n",
    "  #print(temp_data.at[starting_row, starting_col])\n",
    "\n",
    "#mapper(\"Belleville\", \"blah\")\n",
    "\n",
    "#mapper(\"St. Peter\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m output_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_MapFile_polygons.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m field_wb \u001b[38;5;241m=\u001b[39m selected_loc_map\n\u001b[0;32m----> 6\u001b[0m field_ws \u001b[38;5;241m=\u001b[39m \u001b[43mfield_wb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m wb \u001b[38;5;241m=\u001b[39m field_wb\n\u001b[1;32m      8\u001b[0m ws \u001b[38;5;241m=\u001b[39m wb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "output_name = f\"{selected_year}_{selected_location}_MapFile_polygons.csv\"\n",
    "\n",
    "field_wb = selected_loc_map\n",
    "field_ws = field_wb[\"A\"]\n",
    "wb = field_wb\n",
    "ws = wb[\"\"]\n",
    "\n",
    "def mapper(field_name,output_name):    \n",
    "\n",
    "    output_name=output_name\n",
    "\n",
    "    beginning_row = find_head(file_name)  # Ensure this function exists\n",
    "    beginning_col = find_col(file_name)  # Ensure this function exists\n",
    "    idx = 1\n",
    "\n",
    "    for row in ws.iter_rows(max_row=ws.max_row - 1, min_col=19, max_col=19):\n",
    "        for cell in row:\n",
    "            if cell.value == field_name:\n",
    "                starting_row = beginning_row\n",
    "                while starting_row < 60:\n",
    "                    starting_row += 1\n",
    "                    col = beginning_col\n",
    "                    while col < 30:\n",
    "                        col += 1\n",
    "                        plot_value = field_ws.cell(starting_row, col).value\n",
    "                        ws_value = ws.cell(idx, 7).value\n",
    "\n",
    "                        if ws_value is not None:\n",
    "                            ws_value = int(float(ws_value))  # Safe conversion\n",
    "\n",
    "                        if str(plot_value) == str(ws_value):\n",
    "                            # Create the polygon string\n",
    "                            ws.cell(idx, 8).value = (\n",
    "                                f\"POLYGON (({field_ws.cell(beginning_row, col).value} \"\n",
    "                                f\"{field_ws.cell(starting_row, beginning_col).value}, \"\n",
    "                                f\"{field_ws.cell(beginning_row, col).value + 1} \"\n",
    "                                f\"{field_ws.cell(starting_row, beginning_col).value}, \"\n",
    "                                f\"{field_ws.cell(beginning_row, col).value + 1} \"\n",
    "                                f\"{field_ws.cell(starting_row, beginning_col).value + 1}, \"\n",
    "                                f\"{field_ws.cell(beginning_row, col).value} \"\n",
    "                                f\"{field_ws.cell(starting_row, beginning_col).value + 1}, \"\n",
    "                                f\"{field_ws.cell(beginning_row, col).value} \"\n",
    "                                f\"{field_ws.cell(starting_row, beginning_col).value}))\"\n",
    "                            )\n",
    "        idx += 1\n",
    "\n",
    "    # Save the workbook to the output directory\n",
    "    output_path = os.path.join(\"/u/ese/projects-ese/SoyData/advaymb2/output/\", output_name)\n",
    "    wb.save(output_path)\n",
    "\n",
    "    print(f\"File saved: {output_path}\")\n",
    "\n",
    "# Example call (Make sure `find_head` and `find_col` exist)\n",
    "# mapper(\"Belleville\", \"blah\", \"2023\", \"Goodfield\", selected_loc_map, \"input.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36mmapper\u001b[0;34m(field_name, write_to)\u001b[0m\n\u001b[1;32m      2\u001b[0m output_name \u001b[38;5;241m=\u001b[39m selected_year \u001b[38;5;241m+\u001b[39m selected_location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m MapFile-polygons.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m field_wb \u001b[38;5;241m=\u001b[39m selected_loc_map\n\u001b[0;32m----> 4\u001b[0m field_ws \u001b[38;5;241m=\u001b[39m \u001b[43mfield_wb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m wb \u001b[38;5;241m=\u001b[39m field_wb\n\u001b[1;32m      6\u001b[0m ws \u001b[38;5;241m=\u001b[39m wb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'"
     ]
    }
   ],
   "source": [
    "mapper(selected_location, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
